{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11QGWAiiF-VDWaMABmGVjin_odzGWF7XF",
      "authorship_tag": "ABX9TyNVt6I1rognzV+TxVMAesCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenbowler/EmployeeSurvey/blob/main/EmployeeSurvey8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "two page survey read out of googe drive folder, not huggingface"
      ],
      "metadata": {
        "id": "ND4jj3C12PiK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfpEhzEfqQQF"
      },
      "outputs": [],
      "source": [
        "# CELL 1 – Install\n",
        "!apt-get update -qq\n",
        "!apt-get install -y poppler-utils -qq\n",
        "!pip install -q opencv-python pandas matplotlib openai huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2 – Imports & secrets\n",
        "import os, glob, cv2, numpy as np, json, re\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from huggingface_hub import snapshot_download\n",
        "from openai import OpenAI\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "yUxO9BN4qVMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL  3a – link to PNGs in google drive\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')      # your HF token\n",
        "REPO_ID  = userdata.get('REPO_ID')       # e.g. \"you/survey-pngs\"\n",
        "PNG_DIR  = userdata.get('PNG_TARGET_PATH')\n",
        "\n",
        "png_paths = sorted(glob.glob(f\"{PNG_DIR}/**/*.png\", recursive=True))\n",
        "print(f\"Found {len(png_paths)} PNGs\")"
      ],
      "metadata": {
        "id": "ME5Zh6wuz6de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3b with HuggingFace don't run if run 3a – Download PNGs from HF (recursive)\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')      # your HF token\n",
        "REPO_ID  = userdata.get('REPO_ID')       # e.g. \"you/survey-pngs\"\n",
        "PNG_DIR  = \"/content/survey_pngs\"        # mount google drive\n",
        "\n",
        "os.makedirs(PNG_DIR, exist_ok=True)\n",
        "snapshot_download(\n",
        "    repo_id=REPO_ID,\n",
        "    token=HF_TOKEN,\n",
        "    local_dir=PNG_DIR,\n",
        "    repo_type=\"dataset\",\n",
        "    allow_patterns=[\"**/*.png\"],\n",
        "    ignore_patterns=[\"*.json\",\"*.md\"]\n",
        ")\n",
        "\n",
        "png_paths = sorted(glob.glob(f\"{PNG_DIR}/**/*.png\", recursive=True))\n",
        "print(f\"Downloaded {len(png_paths)} PNGs\")"
      ],
      "metadata": {
        "id": "NC29jWohqbJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4 – Pair pages\n",
        "survey_dict = defaultdict(dict)\n",
        "pattern = re.compile(r\"(.+?)_?[ -]?page0*(\\d{1,3})\\.png$\", re.IGNORECASE)\n",
        "\n",
        "for p in png_paths:\n",
        "    m = pattern.search(Path(p).name)\n",
        "    if m:\n",
        "        name, page = m.group(1).strip(), int(m.group(2))\n",
        "        survey_dict[name][page] = p\n",
        "\n",
        "valid_surveys = {k: v for k, v in survey_dict.items() if 1 in v and 2 in v}\n",
        "print(f\"{len(valid_surveys)} complete surveys\")"
      ],
      "metadata": {
        "id": "bdwkeXO9qcue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5 – Pixel-perfect ROI\n",
        "COLS = {'A':(750,38,38), 'B':(910,38,38), 'C':(1070,38,38), 'D':(1230,38,38)}\n",
        "\n",
        "Y_PAGE1 = [208,253,298,343,388,433,478,523,568,613,\n",
        "           658,703,748,793,838,883,928,973,1018,1063]\n",
        "\n",
        "ROIS_PAGE1 = {}\n",
        "for q,y in enumerate(Y_PAGE1,1):\n",
        "    ROIS_PAGE1[q] = {c:(COLS[c][0],y,COLS[c][1],COLS[c][2]) for c in 'ABCD'}\n",
        "\n",
        "ROIS_PAGE2 = {\n",
        "    21: {c:(v[0],208,v[1],v[2]) for c,v in ROIS_PAGE1[1].items()},\n",
        "    22: {c:(v[0],253,v[1],v[2]) for c,v in ROIS_PAGE1[1].items()},\n",
        "    23: {c:(v[0],298,v[1],v[2]) for c,v in ROIS_PAGE1[1].items()}\n",
        "}"
      ],
      "metadata": {
        "id": "Y5G9sPbLqec8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6 – Ultra-aggressive preprocessing (tiny Xs become black)\n",
        "def preprocess(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    eq = cv2.equalizeHist(gray)\n",
        "    clahe = cv2.createCLAHE(clipLimit=6.0, tileGridSize=(8,8))\n",
        "    enhanced = clahe.apply(eq)\n",
        "    kernel = np.ones((11,11), np.uint8)   # huge kernel = catches dots\n",
        "    closed = cv2.morphologyEx(enhanced, cv2.MORPH_CLOSE, kernel)\n",
        "    thresh = cv2.adaptiveThreshold(closed, 255,\n",
        "                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                   cv2.THRESH_BINARY_INV, 71, 30)\n",
        "    return thresh"
      ],
      "metadata": {
        "id": "fVePcWm3qgLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7 – Detect faint marks\n",
        "def is_filled(roi, thresh, ratio=0.18):   # 18 % dark = mark\n",
        "    x,y,w,h = roi\n",
        "    crop = thresh[y:y+h, x:x+w]\n",
        "    if crop.size==0: return False\n",
        "    return np.sum(crop==0)/(w*h) >= ratio"
      ],
      "metadata": {
        "id": "I-2kbsLSqhlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8 – Extract one survey\n",
        "def extract(p1, p2):\n",
        "    answers = ['X']*23\n",
        "    # Page 1\n",
        "    img1 = cv2.imread(p1)\n",
        "    t1 = preprocess(img1)\n",
        "    for q in range(1,21):\n",
        "        for c in 'ABCD':\n",
        "            if is_filled(ROIS_PAGE1[q][c], t1):\n",
        "                answers[q-1] = c\n",
        "                break\n",
        "    # Page 2\n",
        "    img2 = cv2.imread(p2)\n",
        "    t2 = preprocess(img2)\n",
        "    for q in range(21,24):\n",
        "        for c in 'ABCD':\n",
        "            if is_filled(ROIS_PAGE2[q][c], t2):\n",
        "                answers[q-1] = c\n",
        "                break\n",
        "    return answers"
      ],
      "metadata": {
        "id": "4WquTjbpqi4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9 – RUN\n",
        "all_answers = []\n",
        "for name, pages in valid_surveys.items():\n",
        "    print(f\"{name}\")\n",
        "    ans = extract(pages[1], pages[2])\n",
        "    all_answers.append(ans)\n",
        "    print(\"\".join(ans))\n",
        "\n",
        "print(f\"\\n{len(all_answers)} surveys parsed\")"
      ],
      "metadata": {
        "id": "wUdegPFxqkap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 10 – Aggregate\n",
        "stats = defaultdict(lambda: defaultdict(int))\n",
        "for row in all_answers:\n",
        "    for q,ch in enumerate(row,1):\n",
        "        if ch!='X': stats[q][ch] += 1\n",
        "\n",
        "percentages = {}\n",
        "for q,cnt in stats.items():\n",
        "    tot = sum(cnt.values())\n",
        "    per = {c: round(v/tot*100,1) for c,v in cnt.items()}\n",
        "    percentages[q] = dict(sorted(per.items(), key=lambda x:-x[1]))\n",
        "\n",
        "print(\"\\nRESULTS:\")\n",
        "for q in sorted(percentages):\n",
        "    print(f\"Q{q:02d}: {percentages[q]}\")"
      ],
      "metadata": {
        "id": "FH7acQqhqmH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 11 – Grok-4 summary (one call)\n",
        "client = OpenAI(api_key=userdata.get('XAI_API_KEY'), base_url=\"https://api.x.ai/v1\")\n",
        "prompt = f\"\"\"You are a data-analyst.\n",
        "{len(all_answers)} employees answered 23 questions (A=Strongly Agree … D=Strongly Disagree).\n",
        "\n",
        "Percentages:\n",
        "{json.dumps(percentages, indent=2)}\n",
        "\n",
        "Write a concise markdown report with:\n",
        "1. Overall insights\n",
        "2. Table of top answer per question\n",
        "3. Patterns / anomalies\n",
        "4. Visual description\n",
        "5. 3 actionable recommendations\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"grok-4\",\n",
        "    messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "    max_tokens=1500,\n",
        "    temperature=0.3\n",
        ")\n",
        "print(\"\\n### Grok-4 Report\")\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "id": "N87TNf1TqnfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 12 – Charts + CSV\n",
        "fig, axs = plt.subplots(5,5,figsize=(20,20))\n",
        "axs = axs.ravel()\n",
        "colors = {'A':'#2ca02c','B':'#1f77b4','C':'#ff7f0e','D':'#d62728'}\n",
        "for i,(q,per) in enumerate(sorted(percentages.items())):\n",
        "    ch,val = list(per.keys()), list(per.values())\n",
        "    axs[i].bar(ch,val,color=[colors.get(c,'gray') for c in ch])\n",
        "    axs[i].set_title(f'Q{q}'); axs[i].set_ylim(0,100)\n",
        "for ax in axs[len(percentages):]: ax.axis('off')\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "df = pd.DataFrame.from_dict(percentages,orient='index').fillna(0)\n",
        "df.to_csv(\"hf_png_results.csv\")\n",
        "from google.colab import files\n",
        "files.download(\"hf_png_results.csv\")"
      ],
      "metadata": {
        "id": "Fv5YccgnqpKA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
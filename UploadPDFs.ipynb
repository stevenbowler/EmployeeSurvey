{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRYk4risMS1dcNvS0GEpQ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenbowler/EmployeeSurvey/blob/main/UploadPDFs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload PDFs to HuggingFace Private Dataset\n",
        "Steven Bowler\n",
        "\n",
        "https://grok.com/share/bGVnYWN5_6fbd212d-6669-478c-b941-f5c51f0418aa\n",
        "\n",
        "How to Upload\n",
        "\n",
        "1. Prepare Your Repo: Create a new dataset repository on huggingface.co (e.g., via the web UI or CLI: huggingface-cli repo create your-username/pdf-dataset --type dataset).\n",
        "2. Track PDFs with LFS: In your local repo, run git lfs track \"*.pdf\" to ensure large PDFs are stored efficiently. Add this to your .gitattributes file.\n",
        "3. Upload Options:\n",
        "  a. Via Git/CLI (for smaller batches): Use git add . and git commit -m \"Add PDFs\", then git push. For large uploads, enable HF Transfer for speed: pip install huggingface_hub[hf_transfer] and set  HF_HUB_ENABLE_HF_TRANSFER=1.\n",
        "  b. Programmatic (Recommended for 1000 Files): Use the huggingface_hub library to upload folders in chunks:"
      ],
      "metadata": {
        "id": "3wW0tEWcOgSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEeum3T_OZQO"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "api.upload_folder(\n",
        "    folder_path=\"/path/to/your/pdfs\",\n",
        "    repo_id=\"your-username/pdf-dataset\",\n",
        "    repo_type=\"dataset\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This handles LFS automatically and is efficient for many files.\n",
        "If total size is huge, compress PDFs into tarballs (e.g., 100 per file) to reduce the file count.\n",
        "\n",
        "\n",
        "Dataset Structure: Organize PDFs in a folder like /data/pdfs/ and add a README.md or Dataset Card describing the content (e.g., sources, licenses) for better discoverability."
      ],
      "metadata": {
        "id": "8IXU0udpO9m3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a complete, ready-to-run Google Colab notebook code that will:\n",
        "\n",
        "1. Mount Google Drive (where your 1000 PDFs are stored)\n",
        "2. Authenticate with Hugging Face\n",
        "3. Create a new dataset repository (if needed)\n",
        "4. Upload the folder of 1000 PDFs using  upload_folder() with HF Transfer for speed\n",
        "5. Add a basic README.md Dataset Card"
      ],
      "metadata": {
        "id": "Z3BslbkqPXex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 1: Install required packages ===\n",
        "!pip install -q huggingface_hub[hf_transfer] PyPDF2\n",
        "\n",
        "# === STEP 2: Mount Google Drive (where your PDFs are stored) ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# === STEP 3: Login to Hugging Face ===\n",
        "from huggingface_hub import login\n",
        "login()  # This will prompt you to enter your HF token\n",
        "\n",
        "# === STEP 4: Set your paths and repo details ===\n",
        "import os\n",
        "\n",
        "# UPDATE THESE PATHS\n",
        "PDF_FOLDER_PATH = \"/content/drive/MyDrive/pdfs\"  # Folder with your 1000 PDFs\n",
        "REPO_ID = \"your-username/pdf-dataset\"            # Change to your username and dataset name\n",
        "REPO_TYPE = \"dataset\"\n",
        "\n",
        "# Optional: Create a Dataset Card (README.md)\n",
        "README_CONTENT = \"\"\"\n",
        "# PDF Dataset - 1000 Documents\n",
        "\n",
        "This dataset contains 1000 PDF files for research, NLP, or document analysis.\n",
        "\n",
        "## Structure\n",
        "- `pdfs/` - All 1000 PDF files\n",
        "\n",
        "## Usage\n",
        "```python\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"your-username/pdf-dataset\")"
      ],
      "metadata": {
        "id": "2mlDsMhzPNmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
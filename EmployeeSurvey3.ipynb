{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzjjePQ4PaaHqIcyyWCOMm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenbowler/EmployeeSurvey/blob/main/EmployeeSurvey3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpMuLbwHYtMq"
      },
      "outputs": [],
      "source": [
        "#Cell 1 - Install everything\n",
        "!apt-get update -qq\n",
        "!apt-get install -y tesseract-ocr poppler-utils -qq\n",
        "!pip install -q pdf2image huggingface_hub openai pillow pymupdf opencv-python pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - import os, glob, json, base64, cv2, numpy as np\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from pdf2image import convert_from_path\n",
        "from openai import OpenAI\n",
        "from huggingface_hub import snapshot_download\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "# ---- your secrets -------------------------------------------------\n",
        "HF_TOKEN   = userdata.get('HF_TOKEN')      # HF token for private repo\n",
        "REPO_ID    = userdata.get('REPO_ID')       # e.g. \"yourname/survey-pdfs\"\n",
        "XAI_API_KEY= userdata.get('XAI_API_KEY')   # xAI API key\n",
        "PDF_DIR    = userdata.get('PDF_FOLDER_PATH') or \"/content/pdfs\"\n",
        "# ------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "U_QX06OJY6S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 Download PDFs\n",
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "pdf_dir = snapshot_download(\n",
        "    repo_id=REPO_ID,\n",
        "    token=HF_TOKEN,\n",
        "    local_dir=PDF_DIR,\n",
        "    repo_type=\"dataset\",\n",
        "    allow_patterns=[\"*.pdf\"],\n",
        "    ignore_patterns=[\"*.json\",\"*.md\",\"*config*\"]\n",
        ")\n",
        "pdf_paths = sorted(glob.glob(f\"{pdf_dir}/**/*.pdf\", recursive=True))\n",
        "print(f\"Found {len(pdf_paths)} PDF files\")"
      ],
      "metadata": {
        "id": "qMGgYhL1Y8ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - ROI definition (tuned to images)\n",
        "NUM_QUESTIONS = 23          # Q1-20 on page 1, Q21-23 on page 2\n",
        "\n",
        "# (x, y, w, h) for the four columns at DPI=300\n",
        "COL_A = ( 570, 0, 35, 35)   # Strongly Agree\n",
        "COL_B = ( 730, 0, 35, 35)   # Agree\n",
        "COL_C = ( 890, 0, 35, 35)   # Disagree\n",
        "COL_D = (1050, 0, 35, 35)   # Strongly Disagree\n",
        "\n",
        "# y-offset for each question (measured from the top of the page)\n",
        "Y_OFFSETS_PAGE1 = [\n",
        "    205, 250, 295, 340, 385,          # Q1-Q5\n",
        "    430, 475, 520, 565, 610,          # Q6-Q10\n",
        "    655, 700, 745, 790, 835,          # Q11-Q15\n",
        "    880, 925, 970,1015,1060           # Q16-Q20\n",
        "]\n",
        "\n",
        "Y_OFFSETS_PAGE2 = [205, 250, 295]      # Q21-Q23 (same spacing)\n",
        "\n",
        "# Build a dict: page_index → question → list of 4 ROIs\n",
        "CHECKBOX_ROIS = {}\n",
        "# page 0 = first page\n",
        "for q, y in enumerate(Y_OFFSETS_PAGE1, 1):\n",
        "    CHECKBOX_ROIS.setdefault(0, {})[q] = [\n",
        "        (COL_A[0], y+COL_A[1], COL_A[2], COL_A[3]),\n",
        "        (COL_B[0], y+COL_B[1], COL_B[2], COL_B[3]),\n",
        "        (COL_C[0], y+COL_C[1], COL_C[2], COL_C[3]),\n",
        "        (COL_D[0], y+COL_D[1], COL_D[2], COL_D[3]),\n",
        "    ]\n",
        "# page 1 = second page\n",
        "for q, y in enumerate(Y_OFFSETS_PAGE2, 21):\n",
        "    CHECKBOX_ROIS.setdefault(1, {})[q] = [\n",
        "        (COL_A[0], y+COL_A[1], COL_A[2], COL_A[3]),\n",
        "        (COL_B[0], y+COL_B[1], COL_B[2], COL_B[3]),\n",
        "        (COL_C[0], y+COL_C[1], COL_C[2], COL_C[3]),\n",
        "        (COL_D[0], y+COL_D[1], COL_D[2], COL_D[3]),\n",
        "    ]"
      ],
      "metadata": {
        "id": "P0CWKEj0Y_gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5  - Image preprocessing + checkbox detection\n",
        "def preprocess_image(img_cv):\n",
        "    \"\"\"Turn faint grey fills into solid black while keeping empty boxes white.\"\"\"\n",
        "    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 1. Adaptive contrast (CLAHE) – brings out faint marks\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    enhanced = clahe.apply(gray)\n",
        "\n",
        "    # 2. Morphological closing to fill tiny holes inside a mark\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
        "    closed = cv2.morphologyEx(enhanced, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # 3. Adaptive threshold – works on uneven lighting\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        closed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV, 31, 12)\n",
        "\n",
        "    return thresh\n",
        "\n",
        "def is_filled(roi, thresh_img, fill_ratio=0.45):\n",
        "    \"\"\"Return True if at least *fill_ratio* of the ROI is black.\"\"\"\n",
        "    x,y,w,h = roi\n",
        "    crop = thresh_img[y:y+h, x:x+w]\n",
        "    if crop.size == 0:\n",
        "        return False\n",
        "    black = np.sum(crop == 0)\n",
        "    return black / (w*h) >= fill_ratio\n",
        "\n",
        "def extract_answers(pdf_path):\n",
        "    \"\"\"Return list of 23 letters ['A','B',...] or 'X'.\"\"\"\n",
        "    try:\n",
        "        pages = convert_from_path(pdf_path, dpi=300)\n",
        "    except Exception as e:\n",
        "        print(f\"PDF conversion error {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    answers = ['X'] * NUM_QUESTIONS\n",
        "    for page_idx, pil_img in enumerate(pages):\n",
        "        img_cv = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
        "        thresh = preprocess_image(img_cv)\n",
        "\n",
        "        # which questions live on this page?\n",
        "        q_start = 1 if page_idx == 0 else 21\n",
        "        q_end   = 20 if page_idx == 0 else 23\n",
        "\n",
        "        for q in range(q_start, q_end+1):\n",
        "            rois = CHECKBOX_ROIS.get(page_idx, {}).get(q, None)\n",
        "            if not rois:\n",
        "                continue\n",
        "            for col_idx, roi in enumerate(rois, 1):   # 1=A,2=B,3=C,4=D\n",
        "                if is_filled(roi, thresh):\n",
        "                    answers[q-1] = chr(64 + col_idx)   # A=65 …\n",
        "                    break\n",
        "    return answers"
      ],
      "metadata": {
        "id": "CQyFKGMQZAq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 - Process all PDFs\n",
        "all_answers = []\n",
        "for i, p in enumerate(pdf_paths, 1):\n",
        "    print(f\"[{i}/{len(pdf_paths)}] {Path(p).name}\")\n",
        "    ans = extract_answers(p)\n",
        "    if ans and len(ans) == NUM_QUESTIONS:\n",
        "        all_answers.append(ans)\n",
        "    else:\n",
        "        print(\"   → failed / incomplete\")\n",
        "\n",
        "print(f\"\\nSuccessfully parsed {len(all_answers)} / {len(pdf_paths)} PDFs\")"
      ],
      "metadata": {
        "id": "HbHjnnWXZFUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 - Aggregate percentages\n",
        "stats = defaultdict(lambda: defaultdict(int))\n",
        "for row in all_answers:\n",
        "    for q, choice in enumerate(row, 1):\n",
        "        if choice != 'X':\n",
        "            stats[q][choice] += 1\n",
        "\n",
        "percentages = {}\n",
        "total_resp = len(all_answers)\n",
        "for q, cnt in stats.items():\n",
        "    tot = sum(cnt.values())\n",
        "    if tot:\n",
        "        per = {c: round(v/tot*100, 2) for c,v in cnt.items()}\n",
        "        percentages[q] = dict(sorted(per.items(), key=lambda x:-x[1]))\n",
        "\n",
        "print(f\"Total responses: {total_resp}\")\n",
        "for q, p in percentages.items():\n",
        "    print(f\"Q{q:02d}: {p}\")"
      ],
      "metadata": {
        "id": "iSvvtovXZMvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 - One-call Grok 4 summary\n",
        "client = OpenAI(api_key=XAI_API_KEY, base_url=\"https://api.x.ai/v1\")\n",
        "MODEL = \"grok-4\"\n",
        "\n",
        "summary_prompt = f\"\"\"You are a data-analyst.\n",
        "Here are the aggregated results from {total_resp} employees (23 questions, A=Strongly Agree … D=Strongly Disagree).\n",
        "\n",
        "Percentages (most popular first):\n",
        "{json.dumps(percentages, indent=2)}\n",
        "\n",
        "Write a concise professional report with:\n",
        "1. Overall insights (strongest/weakest areas)\n",
        "2. Markdown table of the top answer % per question\n",
        "3. Any noticeable patterns or anomalies\n",
        "4. Short visual description (as if you had bar-charts)\n",
        "5. 2-3 actionable recommendations\n",
        "\n",
        "Use markdown, keep it under 800 words.\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\":\"user\",\"content\":summary_prompt}],\n",
        "    max_tokens=2000,\n",
        "    temperature=0.3\n",
        ")\n",
        "print(\"\\n### Grok-4 Summary Report\")\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "id": "Ag2PJTnsZQGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 - Charts and CSV Report\n",
        "# ----- bar charts -----\n",
        "rows = (NUM_QUESTIONS // 5) + (1 if NUM_QUESTIONS % 5 else 0)\n",
        "fig, axs = plt.subplots(rows, 5, figsize=(22, 4*rows))\n",
        "axs = axs.ravel()\n",
        "\n",
        "for idx, (q, per) in enumerate(percentages.items()):\n",
        "    choices = list(per.keys())\n",
        "    vals    = list(per.values())\n",
        "    axs[idx].bar(choices, vals, color=['#2ca02c','#1f77b4','#ff7f0e','#d62728'])\n",
        "    axs[idx].set_title(f'Q{q}')\n",
        "    axs[idx].set_ylim(0,100)\n",
        "\n",
        "for ax in axs[len(percentages):]:\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ----- CSV -----\n",
        "df = pd.DataFrame(percentages).T.fillna(0)\n",
        "csv_path = f\"{PDF_DIR}/survey_percentages.csv\"\n",
        "df.to_csv(csv_path)\n",
        "print(f\"CSV saved → {csv_path}\")"
      ],
      "metadata": {
        "id": "8M4wL3gVZSLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optional debug - visualize the ROIs on one page\n",
        "def debug_roi(pdf_path, page_idx=0):\n",
        "    pages = convert_from_path(pdf_path, dpi=300)\n",
        "    img = cv2.cvtColor(np.array(pages[page_idx]), cv2.COLOR_RGB2BGR)\n",
        "    for q, rois in CHECKBOX_ROIS.get(page_idx, {}).items():\n",
        "        for col, (x,y,w,h) in enumerate(rois, 1):\n",
        "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "            cv2.putText(img, f\"Q{q}{chr(64+col)}\", (x,y-5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    cv2_imshow(img)\n",
        "\n",
        "debug_roi(pdf_paths[0])   # change index to any PDF you want to inspect"
      ],
      "metadata": {
        "id": "o9PMb9kaZWBP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
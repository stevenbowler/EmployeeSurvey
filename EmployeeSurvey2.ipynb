{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuvliSLuy8iEXyw6Rsccm6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenbowler/EmployeeSurvey/blob/main/EmployeeSurvey2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install dependencies\n",
        "!apt-get update -qq\n",
        "!apt-get install -y tesseract-ocr poppler-utils -qq\n",
        "!pip install -q pdf2image huggingface_hub openai pillow pymupdf"
      ],
      "metadata": {
        "id": "xOcXie4Usun_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports\n",
        "import os\n",
        "import glob\n",
        "import base64\n",
        "import json\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from pdf2image import convert_from_path\n",
        "from openai import OpenAI\n",
        "from huggingface_hub import snapshot_download\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "S_CC0KCCss0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Configuration\n",
        "# Replace with your values\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')  # Your HF token for private repo\n",
        "REPO_ID = userdata.get('REPO_ID')  # e.g., \"user/private-survey-pdfs\"\n",
        "XAI_API_KEY = userdata.get('XAI_API_KEY')  # Get from https://console.x.ai/\n",
        "MODEL = \"grok-4\"  # Or \"grok-4-fast-reasoning\" for cheaper/faster\n",
        "NUM_QUESTIONS = 20  # Corrected to 20 based on PDFs\n",
        "PDF_DIR = userdata.get('PDF_FOLDER_PATH')  # Or set to \"/content/pdfs\""
      ],
      "metadata": {
        "id": "jbVtFPcrsxLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Download PDFs from private HF repo\n",
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "pdf_dir = snapshot_download(\n",
        "    repo_id=REPO_ID,\n",
        "    token=HF_TOKEN,\n",
        "    local_dir=PDF_DIR,\n",
        "    repo_type=\"dataset\",\n",
        "    allow_patterns=[\"*.pdf\"],\n",
        "    ignore_patterns=[\"*.json\", \"*.md\", \"*config*\"]\n",
        ")\n",
        "print(f\"Downloaded PDFs to {pdf_dir}\")\n",
        "\n",
        "pdf_paths = sorted(glob.glob(f\"{pdf_dir}/**/*.pdf\", recursive=True))\n",
        "print(f\"Found {len(pdf_paths)} PDF files\")"
      ],
      "metadata": {
        "id": "XpcgiYvpszbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Initialize xAI client\n",
        "client = OpenAI(\n",
        "    api_key=XAI_API_KEY,\n",
        "    base_url=\"https://api.x.ai/v1\"\n",
        ")"
      ],
      "metadata": {
        "id": "AvnUcip3s2N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Extract answers using Grok-4 Vision\n",
        "def pdf_to_base64(pdf_path):\n",
        "    \"\"\"Convert all pages of PDF to base64 PNGs with higher DPI\"\"\"\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path, dpi=300)  # Increase DPI for better detection\n",
        "        b64s = []\n",
        "        for img in images:\n",
        "            buffered = BytesIO()\n",
        "            img.save(buffered, format=\"PNG\")\n",
        "            b64s.append(base64.b64encode(buffered.getvalue()).decode())\n",
        "        return b64s\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to convert {pdf_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_answers(pdf_path):\n",
        "    \"\"\"Use Grok-4 to extract answers from all PDF page images\"\"\"\n",
        "    b64s = pdf_to_base64(pdf_path)\n",
        "    if not b64s:\n",
        "        return None\n",
        "\n",
        "    prompt_text = \"\"\"You are an expert at reading checkbox-based survey forms.\n",
        "This is a scanned/image employee survey form spanning up to 2 pages with exactly 20 numbered questions (1-20).\n",
        "Ignore section headers (e.g., \"Safe Working Environment\") even if they have checkboxes.\n",
        "Each question is in a table row: question text on the left, then 4 square checkboxes on the right.\n",
        "From left to right: Strongly Agree (A), Agree (B), Disagree (C), Strongly Disagree (D).\n",
        "The selected choice is a filled black square (■); unselected are empty (☐).\n",
        "Identify the single selected choice for each question 1-20.\n",
        "If none selected, multiple selected, or unclear, use \"X\".\n",
        "Return ONLY a valid JSON array of 20 uppercase letters, e.g., [\"A\", \"B\", \"C\", ..., \"D\"].\n",
        "Do not add any other text or explanations.\"\"\"\n",
        "\n",
        "    content = [{\"type\": \"text\", \"text\": prompt_text}]\n",
        "    for b64 in b64s:\n",
        "        content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}})\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": content}],\n",
        "            max_tokens=200,  # Slightly increased for safety\n",
        "            temperature=0  # Deterministic for vision tasks\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "        answers = json.loads(content)\n",
        "        if isinstance(answers, list) and len(answers) == NUM_QUESTIONS:\n",
        "            return [a.upper() for a in answers]\n",
        "        else:\n",
        "            print(f\"Invalid format from {pdf_path}: {content}\")\n",
        "            return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"JSON parse error from {pdf_path}: {content}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"API error for {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Process all PDFs\n",
        "all_answers = []\n",
        "for i, pdf_path in enumerate(pdf_paths):\n",
        "    print(f\"Processing {i+1}/{len(pdf_paths)}: {Path(pdf_path).name}\")\n",
        "    answers = extract_answers(pdf_path)\n",
        "    if answers:\n",
        "        all_answers.append(answers)\n",
        "    else:\n",
        "        print(f\"Skipped {pdf_path} due to extraction failure\")\n",
        "\n",
        "print(f\"Successfully processed {len(all_answers)} / {len(pdf_paths)} PDFs\")"
      ],
      "metadata": {
        "id": "pDYW_BFLs5FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Aggregate percentages (unchanged, but now uses correct NUM_QUESTIONS)\n",
        "question_stats = defaultdict(lambda: defaultdict(int))\n",
        "for answers in all_answers:\n",
        "    for q_idx, choice in enumerate(answers, 1):\n",
        "        question_stats[q_idx][choice] += 1\n",
        "\n",
        "percentages = {}\n",
        "total_responses = len(all_answers)\n",
        "for q, counts in question_stats.items():\n",
        "    total_q = sum(counts.values())\n",
        "    if total_q > 0:\n",
        "        percs = {choice: (count / total_q * 100) for choice, count in counts.items()}\n",
        "        percentages[q] = dict(sorted(percs.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(f\"Total responses: {total_responses}\")\n",
        "print(\"Percentages per question:\")\n",
        "for q, percs in percentages.items():\n",
        "    print(f\"Q{q}: {percs}\")"
      ],
      "metadata": {
        "id": "-tRQOGXWtGnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Generate summary report with Grok-4 (unchanged, but now accurate data)\n",
        "summary_prompt = f\"\"\"You are a data analyst expert.\n",
        "Here is the survey results from {total_responses} respondents for {NUM_QUESTIONS} multiple-choice questions.\n",
        "\n",
        "Percentages (most popular first):\n",
        "{json.dumps(percentages, indent=2)}\n",
        "\n",
        "Generate a professional summary report:\n",
        "1. Overall insights: most consistent questions, popular choices.\n",
        "2. Table of top answer % per question.\n",
        "3. Any patterns or anomalies.\n",
        "4. Visual description (as if charts).\n",
        "5. Recommendations if it were a survey.\n",
        "\n",
        "Use markdown with tables. Be concise yet insightful.\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
        "    max_tokens=2000,\n",
        "    temperature=0.3\n",
        ")\n",
        "\n",
        "print(\"### Grok-4 Expert Summary Report\")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "GyhBnNZ2tL6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Local visualization (bar charts for each question) - adjusted for NUM_QUESTIONS\n",
        "rows = (NUM_QUESTIONS // 5) + (1 if NUM_QUESTIONS % 5 else 0)\n",
        "fig, axes = plt.subplots(rows, 5, figsize=(20, 4 * rows))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, (q, percs) in enumerate(percentages.items()):\n",
        "    choices = list(percs.keys())\n",
        "    vals = list(percs.values())\n",
        "    axes[idx].bar(choices, vals, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
        "    axes[idx].set_title(f'Q{q} (%)')\n",
        "    axes[idx].set_ylim(0, 100)\n",
        "\n",
        "for idx in range(len(percentages), len(axes)):\n",
        "    axes[idx].axis('off')  # Hide unused subplots\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Export to CSV\n",
        "df = pd.DataFrame(percentages).T.fillna(0)\n",
        "df.to_csv(f'{PDF_DIR}/survey_percentages.csv')\n",
        "print(\"Exported to survey_percentages.csv\")"
      ],
      "metadata": {
        "id": "DzieMLJutPqH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
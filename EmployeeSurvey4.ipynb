{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjPa+pcq1H8G0LEGkAwWlH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenbowler/EmployeeSurvey/blob/main/EmployeeSurvey4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvx9hYDzcrO3"
      },
      "outputs": [],
      "source": [
        "# Cell 1 – Install everything\n",
        "!apt-get update -qq\n",
        "!apt-get install -y tesseract-ocr poppler-utils -qq\n",
        "!pip install -q pdf2image huggingface_hub openai pillow pymupdf opencv-python pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 – Imports & secrets (skip HF download for samples; use local)\n",
        "import os, glob, json, cv2, numpy as np\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "from pdf2image import convert_from_path\n",
        "from openai import OpenAI\n",
        "from huggingface_hub import snapshot_download\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import userdata, files  # For optional upload\n",
        "\n",
        "# For samples, set PDF_DIR to current dir or upload\n",
        "HF_TOKEN   = userdata.get('HF_TOKEN')      # HF token for private repo\n",
        "REPO_ID    = userdata.get('REPO_ID')       # e.g. \"yourname/survey-pdfs\"\n",
        "XAI_API_KEY= userdata.get('XAI_API_KEY')   # xAI API key\n",
        "PDF_DIR    = userdata.get('PDF_FOLDER_PATH') or \"/content/pdfs\""
      ],
      "metadata": {
        "id": "JKVNB2xucwGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DON'T USE THIS\n",
        "# Cell 3 – (Skip HF; use local samples or upload)  Find local PDFs (your 6 + template)\n",
        "pdf_paths = sorted(glob.glob(\"Accounting_*.pdf\") + glob.glob(\"Employee Survey v4.pdf\"))\n",
        "if not pdf_paths:\n",
        "    print(\"No PDFs found. Upload via Colab: files.upload()\")\n",
        "    uploaded = files.upload()\n",
        "    pdf_paths = sorted(glob.glob(\"*.pdf\"))\n",
        "print(f\"Found {len(pdf_paths)} PDF files: { [Path(p).name for p in pdf_paths] }\")"
      ],
      "metadata": {
        "id": "JpEAlwhGcx51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "pdf_dir = snapshot_download(\n",
        "    repo_id=REPO_ID,\n",
        "    token=HF_TOKEN,\n",
        "    local_dir=PDF_DIR,\n",
        "    repo_type=\"dataset\",\n",
        "    allow_patterns=[\"*.pdf\"],\n",
        "    ignore_patterns=[\"*.json\",\"*.md\",\"*config*\"]\n",
        ")\n",
        "pdf_paths = sorted(glob.glob(f\"{pdf_dir}/**/*.pdf\", recursive=True))\n",
        "print(f\"Found {len(pdf_paths)} PDF files\")"
      ],
      "metadata": {
        "id": "XIrQzORoenyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "pdf_dir = snapshot_download(\n",
        "    repo_id=REPO_ID,\n",
        "    token=HF_TOKEN,\n",
        "    local_dir=PDF_DIR,\n",
        "    repo_type=\"dataset\",\n",
        "    allow_patterns=[\"*.pdf\"],\n",
        "    ignore_patterns=[\"*.json\",\"*.md\",\"*config*\"]\n",
        ")\n",
        "pdf_paths = sorted(glob.glob(f\"{pdf_dir}/**/*.pdf\", recursive=True))\n",
        "print(f\"Found {len(pdf_paths)} PDF files\")"
      ],
      "metadata": {
        "id": "8NbK_rKuePRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 – Updated ROI definition (shifted + calibrated)\n",
        "NUM_QUESTIONS = 23\n",
        "\n",
        "# Updated columns (shifted right to avoid text overlap; based on your image pixels at DPI=300)\n",
        "COL_A = (650, 0, 35, 35)   # Strongly Agree\n",
        "COL_B = (810, 0, 35, 35)   # Agree\n",
        "COL_C = (970, 0, 35, 35)   # Disagree\n",
        "COL_D = (1130, 0, 35, 35)  # Strongly Disagree\n",
        "\n",
        "# Calibrated y-offsets for page 1 (measured from your attached image: Q1 at ~205px, +45px/row)\n",
        "Y_OFFSETS_PAGE1 = [\n",
        "    205, 250, 295, 340, 385,   # Q1-5\n",
        "    430, 475, 520, 565, 610,   # Q6-10\n",
        "    655, 700, 745, 790, 835,   # Q11-15\n",
        "    880, 925, 970, 1015, 1060  # Q16-20\n",
        "]\n",
        "\n",
        "Y_OFFSETS_PAGE2 = [205, 250, 295]  # Q21-23 (assumed same as top of page 1)\n",
        "\n",
        "# Build ROIs\n",
        "CHECKBOX_ROIS = {}\n",
        "for q, y in enumerate(Y_OFFSETS_PAGE1, 1):\n",
        "    CHECKBOX_ROIS.setdefault(0, {})[q] = [\n",
        "        (COL_A[0], y + COL_A[1], COL_A[2], COL_A[3]),\n",
        "        (COL_B[0], y + COL_B[1], COL_B[2], COL_B[3]),\n",
        "        (COL_C[0], y + COL_C[1], COL_C[2], COL_C[3]),\n",
        "        (COL_D[0], y + COL_D[1], COL_D[2], COL_D[3]),\n",
        "    ]\n",
        "for q, y in enumerate(Y_OFFSETS_PAGE2, 21):\n",
        "    CHECKBOX_ROIS.setdefault(1, {})[q] = [\n",
        "        (COL_A[0], y + COL_A[1], COL_A[2], COL_A[3]),\n",
        "        (COL_B[0], y + COL_B[1], COL_B[2], COL_B[3]),\n",
        "        (COL_C[0], y + COL_C[1], COL_C[2], COL_C[3]),\n",
        "        (COL_D[0], y + COL_D[1], COL_D[2], COL_D[3]),\n",
        "    ]\n",
        "\n",
        "print(\"ROIs calibrated. Ready to process.\")"
      ],
      "metadata": {
        "id": "MclPFuycczA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 – Enhanced preprocessing + detection (extra EQ for low contrast)\n",
        "def preprocess_image(img_cv):\n",
        "    \"\"\"Enhanced for grey fills: Extra histogram EQ + existing pipeline.\"\"\"\n",
        "    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # NEW: Histogram equalization for overall contrast boost (helps grey)\n",
        "    eq = cv2.equalizeHist(gray)\n",
        "\n",
        "    # CLAHE on equalized\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))  # Slightly higher clip\n",
        "    enhanced = clahe.apply(eq)\n",
        "\n",
        "    # Closing to connect faint strokes\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (4,4))  # Slightly larger kernel\n",
        "    closed = cv2.morphologyEx(enhanced, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Adaptive threshold\n",
        "    thresh = cv2.adaptiveThreshold(closed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 35, 10)  # Tweaked params\n",
        "\n",
        "    return thresh\n",
        "\n",
        "def is_filled(roi, thresh_img, fill_ratio=0.40):  # Lowered for sensitivity\n",
        "    x, y, w, h = roi\n",
        "    if y + h > thresh_img.shape[0] or x + w > thresh_img.shape[1]:\n",
        "        return False\n",
        "    crop = thresh_img[y:y+h, x:x+w]\n",
        "    if crop.size == 0:\n",
        "        return False\n",
        "    black = np.sum(crop == 0)\n",
        "    ratio = black / (w * h)\n",
        "    return ratio >= fill_ratio\n",
        "\n",
        "def extract_answers(pdf_path):\n",
        "    try:\n",
        "        pages = convert_from_path(pdf_path, dpi=300)\n",
        "    except Exception as e:\n",
        "        print(f\"Conversion error {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    answers = ['X'] * NUM_QUESTIONS\n",
        "    for page_idx, pil_img in enumerate(pages):\n",
        "        img_cv = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
        "        thresh = preprocess_image(img_cv)\n",
        "\n",
        "        q_start = 1 if page_idx == 0 else 21\n",
        "        q_end = 20 if page_idx == 0 else 23\n",
        "\n",
        "        for q in range(q_start, q_end + 1):\n",
        "            rois = CHECKBOX_ROIS.get(page_idx, {}).get(q)\n",
        "            if not rois:\n",
        "                continue\n",
        "            for col_idx, roi in enumerate(rois, 1):\n",
        "                if is_filled(roi, thresh):\n",
        "                    answers[q-1] = chr(64 + col_idx)  # A=65, B=66, etc.\n",
        "                    break  # Single fill per row\n",
        "    return answers"
      ],
      "metadata": {
        "id": "jqTR3Gh-c1yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 – Process PDFs (now accurate, mixed results)\n",
        "all_answers = []\n",
        "for i, p in enumerate(pdf_paths, 1):\n",
        "    print(f\"[{i}/{len(pdf_paths)}] {Path(p).name}\")\n",
        "    ans = extract_answers(p)\n",
        "    if ans and all(a != 'X' for a in ans[:20]):  # Check page 1 success\n",
        "        all_answers.append(ans)\n",
        "        print(f\"   → Success: {''.join(ans[:5])}... (first 5)\")\n",
        "    else:\n",
        "        print(\"   → Partial/fail (check page 2 or tweak ROIs)\")\n",
        "\n",
        "print(f\"\\nParsed {len(all_answers)} / {len(pdf_paths)} PDFs with valid data\")"
      ],
      "metadata": {
        "id": "dc-ZzmzNc3ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 – Aggregate percentages (expect mixed A/B/C/D)\n",
        "stats = defaultdict(lambda: defaultdict(int))\n",
        "for row in all_answers:\n",
        "    for q, choice in enumerate(row, 1):\n",
        "        if choice != 'X':\n",
        "            stats[q][choice] += 1\n",
        "\n",
        "percentages = {}\n",
        "total_resp = len(all_answers)\n",
        "for q, cnt in stats.items():\n",
        "    tot = sum(cnt.values())\n",
        "    if tot > 0:\n",
        "        per = {c: round(v / tot * 100, 1) for c, v in cnt.items()}\n",
        "        percentages[q] = dict(sorted(per.items(), key=lambda x: -x[1]))\n",
        "\n",
        "print(f\"Total responses: {total_resp}\")\n",
        "for q, p in sorted(percentages.items()):\n",
        "    print(f\"Q{q:2d}: {p}\")"
      ],
      "metadata": {
        "id": "RoLL-SVmc5Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 – Grok-4 summary (1 call)\n",
        "client = OpenAI(api_key=XAI_API_KEY, base_url=\"https://api.x.ai/v1\")\n",
        "MODEL = \"grok-4\"  # Or \"grok-4-fast-reasoning\"\n",
        "\n",
        "summary_prompt = f\"\"\"You are a data analyst.\n",
        "Survey results from {total_resp} respondents (23 Qs: A=Strongly Agree, B=Agree, C=Disagree, D=Strongly Disagree).\n",
        "\n",
        "Percentages (top first):\n",
        "{json.dumps(percentages, indent=2)}\n",
        "\n",
        "Professional markdown report:\n",
        "1. Key insights (e.g., strong agreement areas).\n",
        "2. Table: Q | Top Choice | %\n",
        "3. Patterns/anomalies (e.g., management fairness).\n",
        "4. Chart description.\n",
        "5. 3 recommendations.\n",
        "\n",
        "Concise (<600 words).\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
        "    max_tokens=1500,\n",
        "    temperature=0.3\n",
        ")\n",
        "print(\"\\n### Grok-4 Report\")\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "id": "4I1CQ9kkc6wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 – Charts + CSV Bar charts\n",
        "rows = 5\n",
        "fig, axs = plt.subplots(rows, 5, figsize=(20, 20))\n",
        "axs = axs.ravel()\n",
        "\n",
        "colors = {'A': '#2ca02c', 'B': '#1f77b4', 'C': '#ff7f0e', 'D': '#d62728'}\n",
        "for idx, (q, per) in enumerate(sorted(percentages.items())):\n",
        "    choices = list(per.keys())\n",
        "    vals = list(per.values())\n",
        "    bars = axs[idx].bar(choices, vals, color=[colors.get(c, 'gray') for c in choices])\n",
        "    axs[idx].set_title(f'Q{q}')\n",
        "    axs[idx].set_ylim(0, 100)\n",
        "    # Add % labels\n",
        "    for bar, v in zip(bars, vals):\n",
        "        axs[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{v}%', ha='center', va='bottom')\n",
        "\n",
        "for ax in axs[len(percentages):]:\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# CSV\n",
        "df = pd.DataFrame.from_dict(percentages, orient='index').fillna(0)\n",
        "csv_path = f\"{PDF_DIR}survey_results_fixed.csv\"\n",
        "df.to_csv(csv_path)\n",
        "print(f\"Exported: {csv_path}\")\n",
        "files.download(csv_path)  # Auto-download"
      ],
      "metadata": {
        "id": "s-njXJnIc9dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 10 - Visualize ROIs\n",
        "def debug_extract(pdf_path, page_idx=0, save_thresh=False):\n",
        "    pages = convert_from_path(pdf_path, dpi=300)\n",
        "    img_cv = cv2.cvtColor(np.array(pages[page_idx]), cv2.COLOR_RGB2BGR)\n",
        "    thresh = preprocess_image(img_cv)\n",
        "\n",
        "    # Draw ROIs\n",
        "    for q, rois in CHECKBOX_ROIS.get(page_idx, {}).items():\n",
        "        for col, roi in enumerate(rois, 1):\n",
        "            x, y, w, h = roi\n",
        "            color = (0, 255, 0) if is_filled(roi, thresh) else (0, 0, 255)\n",
        "            cv2.rectangle(img_cv, (x, y), (x+w, y+h), color, 2)\n",
        "            cv2.putText(img_cv, f\"Q{q}{chr(64+col)}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)\n",
        "\n",
        "    # Show original with boxes\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    print(\"Original with ROIs (green=filled, red=empty):\")\n",
        "    cv2_imshow(img_cv)\n",
        "\n",
        "    # Show threshold (black=potential fill)\n",
        "    print(\"Threshold image (black areas = detected marks):\")\n",
        "    cv2_imshow(thresh)\n",
        "\n",
        "    if save_thresh:\n",
        "        cv2.imwrite('thresh_debug.png', thresh)\n",
        "        files.download('thresh_debug.png')\n",
        "\n",
        "# Run on first PDF\n",
        "debug_extract(pdf_paths[0])"
      ],
      "metadata": {
        "id": "tu07rMUYdA3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}